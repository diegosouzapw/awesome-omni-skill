{
  "name": "llm-evaluation",
  "description": "Implement comprehensive evaluation strategies for LLM applications using automated metrics, human feedback, and benchmarking. Use when testing LLM performance, measuring AI application quality, or ...",
  "category": "data-ai",
  "canonical_category": "data-ai",
  "repository": "sickn33/antigravity-awesome-skills",
  "repository_url": "https://github.com/sickn33/antigravity-awesome-skills",
  "author": "sickn33",
  "author_avatar": "https://github.com/sickn33.png",
  "file_path": "web-app/public/skills/llm-evaluation/SKILL.md",
  "source": "github_curated_repos",
  "stars": 15461,
  "quality_score": 95,
  "best_practices_score": 90,
  "skill_level": 3,
  "skill_level_label": "resources",
  "has_scripts": true,
  "has_extra_files": false,
  "downloads": 0,
  "content_hash": "f73d8fbfdf8f935c0a0a27816d539ae58d243d1626fcb10a2986a1851a0e6526",
  "indexed_at": "2026-02-25T17:24:43.593Z",
  "synced_at": "2026-02-28T04:18:02.777Z",
  "omni_registry_url": "https://omni-skill-registry.omniroute.online/#/skill/f8a1d3a5554347e0ffdfb2baadabb20587aff7fce13717e9dd9bf1c7cf82f14f",
  "install_command": "mkdir -p .claude/skills/llm-evaluation && curl -sL \"https://raw.githubusercontent.com/sickn33/antigravity-awesome-skills/main/web-app/public/skills/llm-evaluation/SKILL.md\" > .claude/skills/llm-evaluation/SKILL.md",
  "raw_url": "https://raw.githubusercontent.com/sickn33/antigravity-awesome-skills/main/web-app/public/skills/llm-evaluation/SKILL.md"
}
