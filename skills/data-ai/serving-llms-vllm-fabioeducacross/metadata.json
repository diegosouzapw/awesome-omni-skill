{
  "name": "serving-llms-vllm",
  "description": "Serves LLMs with high throughput using vLLM's PagedAttention and continuous batching. Use when deploying production LLM APIs, optimizing inference latency/throughput, or serving models with limited GPU memory. Supports OpenAI-compatible endpoints, quantization (GPTQ/AWQ/FP8), and tensor parallelism.",
  "category": "data-ai",
  "canonical_category": "data-ai",
  "repository": "fabioeducacross/DesignSystem-Vuexy",
  "repository_url": "https://github.com/fabioeducacross/DesignSystem-Vuexy",
  "author": "fabioeducacross",
  "author_avatar": "https://github.com/fabioeducacross.png",
  "file_path": ".agents/skills/serving-llms-vllm/SKILL.md",
  "source": "github_code_search",
  "stars": 0,
  "quality_score": 48,
  "best_practices_score": 90,
  "skill_level": 3,
  "skill_level_label": "resources",
  "has_scripts": true,
  "has_extra_files": true,
  "downloads": 0,
  "content_hash": "321f7bcd8e8c7399e5097b61fedd6ab58680df524a35df3dc5f453ba8b005913",
  "indexed_at": "2026-02-26T12:18:21.979Z",
  "synced_at": "2026-02-27T02:48:44.702Z",
  "omni_registry_url": "https://omni-skill-registry.omniroute.online/#/skill/94decd4b3ca37affc6705e912d1064711ab1d600ab197482f4ca3f0448d39ce2",
  "install_command": "mkdir -p .claude/skills/serving-llms-vllm && curl -sL \"https://raw.githubusercontent.com/fabioeducacross/DesignSystem-Vuexy/main/.agents/skills/serving-llms-vllm/SKILL.md\" > .claude/skills/serving-llms-vllm/SKILL.md",
  "raw_url": "https://raw.githubusercontent.com/fabioeducacross/DesignSystem-Vuexy/main/.agents/skills/serving-llms-vllm/SKILL.md"
}
