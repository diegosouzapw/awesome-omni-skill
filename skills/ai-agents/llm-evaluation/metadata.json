{
  "name": "llm-evaluation",
  "description": "Implement comprehensive evaluation strategies for LLM applications using automated metrics, human feedback, and benchmarking. Use when testing LLM performance, measuring AI application quality, or ...",
  "category": "ai-agents",
  "canonical_category": "ai-agents",
  "repository": "sickn33/antigravity-awesome-skills",
  "repository_url": "https://github.com/sickn33/antigravity-awesome-skills",
  "author": "sickn33",
  "author_avatar": "https://github.com/sickn33.png",
  "file_path": "skills/llm-evaluation/SKILL.md",
  "source": "github_curated_repos",
  "stars": 16719,
  "quality_score": 95,
  "best_practices_score": 85,
  "skill_level": 3,
  "skill_level_label": "resources",
  "has_scripts": true,
  "has_extra_files": false,
  "downloads": 0,
  "content_hash": "4cc9f11f2cbc5ae04ed77239dd378df4abaec236532c43ba2b821fff89e89166",
  "indexed_at": "2026-02-28T04:41:51.225Z",
  "synced_at": "2026-02-28T06:13:04.210Z",
  "omni_registry_url": "https://omni-skill-registry.omniroute.online/#/skill/da012528db295d941e114aee02b617963c65998ef2b0203031b6f6243c74979d",
  "install_command": "mkdir -p .claude/skills/llm-evaluation && curl -sL \"https://raw.githubusercontent.com/sickn33/antigravity-awesome-skills/main/skills/llm-evaluation/SKILL.md\" > .claude/skills/llm-evaluation/SKILL.md",
  "raw_url": "https://raw.githubusercontent.com/sickn33/antigravity-awesome-skills/main/skills/llm-evaluation/SKILL.md"
}
