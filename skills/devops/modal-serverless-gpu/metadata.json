{
  "name": "modal-serverless-gpu",
  "description": "Serverless GPU cloud platform for running ML workloads. Use when you need on-demand GPU access without infrastructure management, deploying ML models as APIs, or running batch jobs with automatic scaling.",
  "category": "devops",
  "canonical_category": "devops",
  "repository": "Orchestra-Research/AI-Research-SKILLs",
  "repository_url": "https://github.com/Orchestra-Research/AI-Research-SKILLs",
  "author": "Orchestra-Research",
  "author_avatar": "https://github.com/Orchestra-Research.png",
  "file_path": "09-infrastructure/modal/SKILL.md",
  "source": "github_code_search",
  "stars": 0,
  "quality_score": 48,
  "best_practices_score": 90,
  "skill_level": 3,
  "skill_level_label": "resources",
  "has_scripts": true,
  "has_extra_files": true,
  "downloads": 0,
  "content_hash": "93434dc723e3a8ac3d07edf9a8bdbb2116161b958003b1f5e9bb9599346caabe",
  "indexed_at": "2026-02-26T10:46:10.342Z",
  "synced_at": "2026-02-27T02:40:05.185Z",
  "omni_registry_url": "https://omni-skill-registry.omniroute.online/#/skill/23e1ad0e063447c31abbbd81634416ea8e368db98ca8cbba46353836cb92555e",
  "install_command": "mkdir -p .claude/skills/modal-serverless-gpu && curl -sL \"https://raw.githubusercontent.com/Orchestra-Research/AI-Research-SKILLs/main/09-infrastructure/modal/SKILL.md\" > .claude/skills/modal-serverless-gpu/SKILL.md",
  "raw_url": "https://raw.githubusercontent.com/Orchestra-Research/AI-Research-SKILLs/main/09-infrastructure/modal/SKILL.md"
}
